{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daftar Isi:\n",
    "- [1. Akusisi Data](#1-akusisi-data)\n",
    "- [2. Pembentukan Kamus Slang](#2-pembentukan-kamus-slang)\n",
    "- [3. Anotasi Data](#3-anotasi-data)\n",
    "- [4. Prapemrosesan](#4-prapemrosesan)\n",
    "- [5. Pemodelan SVM](#5-pemodelan-svm)\n",
    "- [6. Pengukuran Performa](#6-pengukuran-performa)\n",
    "    - [6.1 Pengukuran Performa Tahap 1](#61-pengukuran-performa-tahap-1)\n",
    "    - [6.2 Pengukuran Performa Tahap 2](#62-pengukuran-performa-tahap-2)\n",
    "- [7. Pengujian](#7-pengujian)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Internal link tidak berfungsi di laman github.___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: F. Waskito\n",
      "\n",
      "Last updated: Mon Jun 05 2023 21:26:49\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.16\n",
      "IPython version      : 8.12.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -a \"F. Waskito\" -n -t -u -v"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __1. Akusisi Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping: 100%|██████████| 476/476 [00:39<00:00, 12.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from collection.scrape import TweetScraper\n",
    "\n",
    "scraper = TweetScraper(\n",
    "    \"depresi OR bipolar\",\n",
    "    \"id\",\n",
    "    \"2022-05-10\",\n",
    "    \"2022-05-11\",\n",
    ")\n",
    "\n",
    "scraper.scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/tweet/scrape/depresi_or_bipolar_tweets_id_220510_with_irrelevant.csv\"\n",
    "scraper.tweets_table.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets before removal: 476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing irrelevant: 100%|██████████| 476/476 [07:44<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets after removal: 428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of tweets before removal: {scraper.n_tweets}\")\n",
    "\n",
    "irrelevant_tweets_table = scraper.remove_irrelevant()\n",
    "print(f\"Number of tweets after removal: {scraper.n_tweets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/tweet/scrape/depresi_or_bipolar_tweets_id_220510_irrelevant.csv\"\n",
    "irrelevant_tweets_table.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/scrape/depresi_or_bipolar_tweets_id_220510.csv\"\n",
    "scraper.tweets_table.to_csv(path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __2. Pembentukan Kamus Slang__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beralih ke:\n",
    "- [1. Akusisi Data](#1-akusisi-data)\n",
    "- [3. Anotasi Data](#3-anotasi-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3409 entries, 0 to 3408\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Tweet_ID  3409 non-null   int64 \n",
      " 1   Datetime  3409 non-null   object\n",
      " 2   Username  3409 non-null   object\n",
      " 3   Text      3409 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 106.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "path = \"data/tweet/scrape/depresi_or_bipolar_tweets_id_01-10.csv\"\n",
    "tweets_table = pandas.read_csv(path)\n",
    "tweets_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3409/3409 [4:22:04<00:00,  4.61s/it]  \n"
     ]
    }
   ],
   "source": [
    "from collection.slang.template import KamusSlangTemplate\n",
    "\n",
    "template = KamusSlangTemplate(tweets_table['Text'])\n",
    "template.create()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Catatan__: Karena dalam proses pencarian slang dibutuhkan parapemrosesan teks sampai di tahap *stemming* (menggunakan Sastrawi), ketidakefisienan waktu jadi konsekuensinya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5357 entries, 0 to 5356\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Slang       5357 non-null   object \n",
      " 1   Makna       0 non-null      float64\n",
      " 2   No_Konteks  5357 non-null   int64  \n",
      " 3   Konteks     5357 non-null   object \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 167.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slang</th>\n",
       "      <th>Makna</th>\n",
       "      <th>No_Konteks</th>\n",
       "      <th>Konteks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ilux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Padahal ilux baru KB/TK ya mana ngerti begitua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Padahal ilux baru KB/TK ya mana ngerti begitua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Padahal ilux baru KB/TK ya mana ngerti begitua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Padahal ilux baru KB/TK ya mana ngerti begitua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ngerti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Padahal ilux baru KB/TK ya mana ngerti begitua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Slang  Makna  No_Konteks  \\\n",
       "0    ilux    NaN           0   \n",
       "1      kb    NaN           0   \n",
       "2      tk    NaN           0   \n",
       "3      ya    NaN           0   \n",
       "4  ngerti    NaN           0   \n",
       "\n",
       "                                             Konteks  \n",
       "0  Padahal ilux baru KB/TK ya mana ngerti begitua...  \n",
       "1  Padahal ilux baru KB/TK ya mana ngerti begitua...  \n",
       "2  Padahal ilux baru KB/TK ya mana ngerti begitua...  \n",
       "3  Padahal ilux baru KB/TK ya mana ngerti begitua...  \n",
       "4  Padahal ilux baru KB/TK ya mana ngerti begitua...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.template.info()\n",
    "template.template.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/dictionary/kamus_slang.csv\"\n",
    "template.template.to_csv(path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __3. Anotasi Twit__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beralih ke:\n",
    "- [2. Pembentukan Kamus Slang](#2-pembentukan-kamus-slang)\n",
    "- [4. Prapemrosesan](#4-prapemrosesan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3409 entries, 0 to 3408\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Tweet_ID  3409 non-null   float64\n",
      " 1   Datetime  3409 non-null   object \n",
      " 2   Username  3409 non-null   object \n",
      " 3   Text      3409 non-null   object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 106.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "path = \"data/tweet/scrape/depresi_or_bipolar_tweets_id_01-10.csv\"\n",
    "tweets_table = pandas.read_csv(path)\n",
    "tweets_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "labeling: 100%|██████████| 3409/3409 [31:51<00:00,  1.78it/s]  \n"
     ]
    }
   ],
   "source": [
    "from collection.annotation import BlobLabeler\n",
    "\n",
    "anotator = BlobLabeler(tweets_table[\"Text\"])\n",
    "anotator.generate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Catatan__: Lama waktu proses pelabelan lebih dipengaruhi oleh dua faktor, koneksi internet dan versi Python. Pelabelan ini hampir 2 kali lebih cepat dari proses pelabelan sebelumnya. Menggunakan *dependecies* yang persis sama, proses sebelumnya memakan waktu di atas 55 menit ketika dilakukan di jam aktif dan melalui Python 3.10.x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "\t('positive', 864)\n",
      "\t('neutral', 1253)\n",
      "\t('negative', 1292)\n"
     ]
    }
   ],
   "source": [
    "from collection import analysis\n",
    "\n",
    "analysis.get_distribution(anotator.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3409 entries, 0 to 3408\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Tweet_ID   3409 non-null   float64\n",
      " 1   Datetime   3409 non-null   object \n",
      " 2   Username   3409 non-null   object \n",
      " 3   Text       3409 non-null   object \n",
      " 4   Sentiment  3409 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 133.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.520554e+18</td>\n",
       "      <td>2022-05-01 00:00:12+00:00</td>\n",
       "      <td>yfnasa</td>\n",
       "      <td>Padahal ilux baru KB/TK ya mana ngerti begitua...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.520561e+18</td>\n",
       "      <td>2022-05-01 00:30:46+00:00</td>\n",
       "      <td>SoleilLumina</td>\n",
       "      <td>Et dah gw jadi ngefollow akun quotes depresi (...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.520563e+18</td>\n",
       "      <td>2022-05-01 00:36:48+00:00</td>\n",
       "      <td>petitegeeky</td>\n",
       "      <td>Rossy setahun di laut betah, cuma pas pulang a...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.520565e+18</td>\n",
       "      <td>2022-05-01 00:43:40+00:00</td>\n",
       "      <td>raniapj</td>\n",
       "      <td>Sebenarnya aku jarang jbjb. Aku toh lagi stres...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.520565e+18</td>\n",
       "      <td>2022-05-01 00:43:50+00:00</td>\n",
       "      <td>Jawaban</td>\n",
       "      <td>Apakah kamu sedang banyak masalah, sampai-samp...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet_ID                   Datetime      Username  \\\n",
       "0  1.520554e+18  2022-05-01 00:00:12+00:00        yfnasa   \n",
       "1  1.520561e+18  2022-05-01 00:30:46+00:00  SoleilLumina   \n",
       "2  1.520563e+18  2022-05-01 00:36:48+00:00   petitegeeky   \n",
       "3  1.520565e+18  2022-05-01 00:43:40+00:00       raniapj   \n",
       "4  1.520565e+18  2022-05-01 00:43:50+00:00       Jawaban   \n",
       "\n",
       "                                                Text Sentiment  \n",
       "0  Padahal ilux baru KB/TK ya mana ngerti begitua...  positive  \n",
       "1  Et dah gw jadi ngefollow akun quotes depresi (...   neutral  \n",
       "2  Rossy setahun di laut betah, cuma pas pulang a...   neutral  \n",
       "3  Sebenarnya aku jarang jbjb. Aku toh lagi stres...   neutral  \n",
       "4  Apakah kamu sedang banyak masalah, sampai-samp...   neutral  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_table[\"Sentiment\"] = anotator.labels\n",
    "\n",
    "tweets_table.info()\n",
    "tweets_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/tweet/depresi_or_bipolar_tweets_id_01-10.csv\"\n",
    "tweets_table.to_csv(path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __4. Prapemrosesan__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beralih ke:\n",
    "- [3. Anotasi Data](#3-anotasi-data)\n",
    "- [5. Pemodelan SVM](#5-pemodelan-svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Author: F. Waskito\n",
      "\n",
      "Last updated: Thu Jun 08 2023 07:16:59\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.16\n",
      "IPython version      : 8.12.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import sklearnex\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "sklearnex.patch_sklearn()\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -a \"F. Waskito\" -n -t -u -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3409 entries, 0 to 3408\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Tweet_ID   3409 non-null   float64\n",
      " 1   Datetime   3409 non-null   object \n",
      " 2   Username   3409 non-null   object \n",
      " 3   Text       3409 non-null   object \n",
      " 4   Sentiment  3409 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 133.3+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "path = \"data/tweet/depresi_or_bipolar_tweets_id_01-10.csv\"\n",
    "tweets_table = pandas.read_csv(path)\n",
    "tweets_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3409,)\n",
      "Distribution:\n",
      "\t('positive', 864)\n",
      "\t('neutral', 1253)\n",
      "\t('negative', 1292)\n"
     ]
    }
   ],
   "source": [
    "from collection import analysis\n",
    "\n",
    "texts = tweets_table.loc[:, \"Text\"].copy().to_list()\n",
    "labels = tweets_table.loc[:, \"Sentiment\"].copy().to_list()\n",
    "\n",
    "analysis.get_shape(texts)\n",
    "analysis.get_distribution(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Praoperasi Numerik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3409/3409 [10:36<00:00,  5.36it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from preprocess.preprocessing import TextPreprocessor\n",
    "\n",
    "preprocessor = TextPreprocessor()\n",
    "for i, text in enumerate(tqdm(texts)):\n",
    "    text = preprocessor.clean(text)\n",
    "    text = preprocessor.standardize(text)\n",
    "    tokens = preprocessor.tokenize(text)\n",
    "    tokens = preprocessor.filter(tokens)\n",
    "    texts[i] = preprocessor.stem(tokens)\n",
    "    time.sleep(0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: Manipulasi data dengan ukuran sama (3409 cuitan), melalui Python versi 3.10.x atau 3.11.x waktu *runtime* praoperasi numerik (dengan dan atau *negation handling*) hampir selalu di di kisaran 12m 30s s.d. 13m."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Ekstraksi Fitur"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2.1 Ekstraksi Fitur dengan Bag of Words (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess.feature.extraction import TextVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3409, 4949)\n"
     ]
    }
   ],
   "source": [
    "extractor = TextVectorizer(texts)\n",
    "extractor.transform(target=\"bow\", min_df=1)\n",
    "vector_texts = extractor.vectors\n",
    "\n",
    "analysis.get_shape(vector_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'depresi'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.vocabs[1005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 2, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_texts[4][1000:1010]\n",
    "vector_texts[1151][1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0. , 0. , 0. ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.  , 0.  ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dengan normalisasi\n",
    "extractor.transform(target=\"bow\", min_df=1, norm=True)\n",
    "extractor.vectors[4][1000:1010]\n",
    "extractor.vectors[1151][1000:1010]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vektor BOW representasi teks dokumen (cuitan) yang akan digunakan adalah vetor BOW yeng telah dilakukan dua proses sekuender lainnya yaitu:\n",
    "- Normaliasi dengan penskalaan \"Min-Max\"\n",
    "- Reduksi n (banyak) fitur menaikkan nilai DF (frekuensi kemunculan *term* t dalam dokuemen d) = 2. Dengan kata lain, setiap fitur (*term*/elemen di setiap vektor) yang hanya memiliki nilai pada 1 (satu) buah vektor, maka fitur tersebut akan dihapus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3409, 2205)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dengan normaliasi dan min. DF adalah 2\n",
    "extractor = TextVectorizer(texts)\n",
    "extractor.transform(target=\"bow\", min_df=2, norm=True)\n",
    "vector_texts = extractor.vectors\n",
    "\n",
    "analysis.get_shape(vector_texts)\n",
    "vector_texts[4][1000:1010]\n",
    "vector_texts[1151][1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kognitif'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perpindahan indeks fitur setelah menaikkan DF = 2\n",
    "extractor.vocabs[1005]\n",
    "extractor.vocabs.index(\"depresi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0. , 0. , 0. , 0. , 0.5, 0. , 0. , 0. , 0. ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.  , 0.  ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_texts[4][445:455]\n",
    "vector_texts[1151][445:455]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2.2 Ektraksi Fitur dengaN Term Frequency-Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3409, 4949)\n"
     ]
    }
   ],
   "source": [
    "extractor = TextVectorizer(texts)\n",
    "extractor.transform(target=\"tfidf\", min_df=1)\n",
    "vector_texts = extractor.vectors\n",
    "\n",
    "analysis.get_shape(vector_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       2.24489866, 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       1.12244933, 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_texts[4][1000:1010]\n",
    "vector_texts[1151][1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.11688664, 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03385865, 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dengan normalisasi\n",
    "extractor.transform(target=\"tfidf\", min_df=1, norm=True)\n",
    "extractor.vectors[4][1000:1010]\n",
    "extractor.vectors[1151][1000:1010]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vektor TF-IDF representasi teks dokumen (cuitan) yang akan digunakan adalah vetor TF-IDF yeng telah dilakukan dua proses sekuender lainnya yaitu:\n",
    "- Normaliasi dengan penskalaan \"L2\" (Euclidean/Akar Kuadrat)\n",
    "- Reduksi n fitur juga sama sebagaimana dilakukan pada vektor BOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3409, 2205)\n"
     ]
    }
   ],
   "source": [
    "extractor = TextVectorizer(texts)\n",
    "extractor.transform(target=\"tfidf\", min_df=2, norm=True)\n",
    "vector_texts = extractor.vectors\n",
    "\n",
    "analysis.get_shape(vector_texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Transformasi Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess.encoding import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:\n",
      "\t(2, 864)\n",
      "\t(1, 1253)\n",
      "\t(0, 1292)\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder(labels)\n",
    "encoder.transform(target=\"integer\")\n",
    "encoded_labels = encoder.encoded_labels\n",
    "\n",
    "analysis.get_distribution(encoded_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4 Seprasi Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Train set:\n",
      "Shape: (2386, 2205)\n",
      "Distribution:\n",
      "\t(1, 866)\n",
      "\t(2, 619)\n",
      "\t(0, 901)\n",
      "\n",
      "> Test set:\n",
      "Shape: (1023, 2205)\n",
      "Distribution:\n",
      "\t(0, 391)\n",
      "\t(1, 387)\n",
      "\t(2, 245)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    vector_texts,\n",
    "    encoded_labels,\n",
    "    test_size = 0.3,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "print(\"> Train set:\")\n",
    "analysis.get_shape(X_train)\n",
    "analysis.get_distribution(y_train)\n",
    "print(\"\\n> Test set:\")\n",
    "analysis.get_shape(X_test)\n",
    "analysis.get_distribution(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __5. Pemodelan SVM__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beralih ke:\n",
    "- [4. Prapemrosesan](#4-prapemrosesan)\n",
    "- [6. Pengukuran Performa](#6-pengukuran-performa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 100.0\n",
    "gamma = 1.0\n",
    "degree = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm = SVC(kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svm = SVC(kernel=\"rbf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_svm = SVC(kernel=\"poly\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __6. Pengukuran Performa__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beralih ke:\n",
    "- [5. Pemodelan SVM](#5-pemodelan-svm)\n",
    "- [6.2 Pengukuran Performa SVM + TF-IDF](#62-pengukuran-performa-svm--tf-idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validation.cross import ImbalancedCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "scoring = [\"accuracy\", \"precision\", \"recall\", \"f1\",]\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV: 100%|██████████| 5/5 [00:17<00:00,  3.44s/it]\n"
     ]
    }
   ],
   "source": [
    "linear_perform = ImbalancedCV(\n",
    "    model = linear_svm,\n",
    "    n_fold = n_fold,\n",
    "    scoring = scoring,\n",
    "    scoring_avg = \"macro\",\n",
    "    random_state = random_state,\n",
    ")\n",
    "\n",
    "linear_perform.validate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV: 100%|██████████| 5/5 [00:17<00:00,  3.57s/it]\n"
     ]
    }
   ],
   "source": [
    "rbf_perform = ImbalancedCV(\n",
    "    model = rbf_svm,\n",
    "    n_fold = n_fold,\n",
    "    scoring = scoring,\n",
    "    scoring_avg = \"macro\",\n",
    "    random_state = random_state,\n",
    ")\n",
    "\n",
    "rbf_perform.validate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV: 100%|██████████| 5/5 [00:19<00:00,  3.88s/it]\n"
     ]
    }
   ],
   "source": [
    "poly_perform = ImbalancedCV(\n",
    "    model = poly_svm,\n",
    "    n_fold = n_fold,\n",
    "    scoring = scoring,\n",
    "    scoring_avg = \"macro\",\n",
    "    random_state = random_state,\n",
    ")\n",
    "\n",
    "poly_perform.validate(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1 Pengukuran Performa SVM + BOW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beralih ke:\n",
    "- [6. Pengukuran Performa](#6-pengukuran-performa)\n",
    "- [6.2 Pengukuran Performa SVM + TF-IDF](#62-pengukuran-performa-svm--tf-idf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1.1 Performa SVM-Linier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_accuracy': 0.672,\n",
       " 'mean_precision': 0.662,\n",
       " 'mean_recall': 0.657,\n",
       " 'mean_f1': 0.654}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_perform.get_score() # default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_accuracy': 0.692,\n",
       " 'mean_precision': 0.687,\n",
       " 'mean_recall': 0.681,\n",
       " 'mean_f1': 0.678}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_perform.get_score() # C= 1.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1.3 Performa SVM-RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_accuracy': 0.637,\n",
       " 'mean_precision': 0.633,\n",
       " 'mean_recall': 0.606,\n",
       " 'mean_f1': 0.602}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_perform.get_score() # default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_accuracy': 0.523,\n",
       " 'mean_precision': 0.596,\n",
       " 'mean_recall': 0.508,\n",
       " 'mean_f1': 0.468}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_perform.get_score() # C= 1.0; gamma= 0.01"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1.2 Performa SVM-Polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_accuracy': 0.387,\n",
       " 'mean_precision': 0.761,\n",
       " 'mean_recall': 0.361,\n",
       " 'mean_f1': 0.234}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_perform.get_score() # default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_accuracy': 0.368,\n",
       " 'mean_precision': 0.256,\n",
       " 'mean_recall': 0.335,\n",
       " 'mean_f1': 0.182}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_perform.get_score() # C= 1.0; gamma= 0.01; degree= 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2 Pengukuran Performa SVM + TF-IDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beralih ke:\n",
    "- [5. Pemodelan SVM](#5-pemodelan-svm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2.1 Performa SVM-Linier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_accuracy': 0.696,\n",
       " 'mean_precision': 0.685,\n",
       " 'mean_recall': 0.682,\n",
       " 'mean_f1': 0.683}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_perform.get_score() # default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_accuracy': 0.712,\n",
       " 'mean_precision': 0.701,\n",
       " 'mean_recall': 0.698,\n",
       " 'mean_f1': 0.698}"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_perform.get_score() # C= 1.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2.2 Performa SVM-RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_accuracy': 0.7,\n",
       " 'mean_precision': 0.707,\n",
       " 'mean_recall': 0.672,\n",
       " 'mean_f1': 0.674}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_perform.get_score() # default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_accuracy': 0.456,\n",
       " 'mean_precision': 0.646,\n",
       " 'mean_recall': 0.496,\n",
       " 'mean_f1': 0.419}"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_perform.get_score() # C= 1.0; gamma= 0.01"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2.3 Performa SVM-Polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_accuracy': 0.585,\n",
       " 'mean_precision': 0.647,\n",
       " 'mean_recall': 0.55,\n",
       " 'mean_f1': 0.541}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_perform.get_score() # default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_accuracy': 0.427,\n",
       " 'mean_precision': 0.753,\n",
       " 'mean_recall': 0.39,\n",
       " 'mean_f1': 0.291}"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_perform.get_score() # C= 1.0; gamma= 0.01; degree= 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beralih ke:\n",
    "- [Pengukuran Performa SVM + TF-IDF](#62-pengukuran-performa-svm--tf-idf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __7. Pengujian__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beralih ke:\n",
    "- [6.2 Pengukuran Performa Tahap 2](#62-pengukuran-performa-tahap-2)\n",
    "- [Daftar Isi](#daftar-isi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoter = SMOTE()\n",
    "balanced_X_train, balanced_y_train = smoter.fit_resample(\n",
    "    X_train,\n",
    "    y_train\n",
    ")\n",
    "\n",
    "analysis.get_shape(X_train)\n",
    "analysis.get_distribution(y_train)\n",
    "analysis.get_shape(balanced_X_train)\n",
    "analysis.get_distribution(balanced_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, )}\\n\")\n",
    "# print(f\"Report:\\n {classification_report(y_test, )}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a866adf8194fa61f189944e84fd4593acc60ea224cd56c5077b5e0209d174b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
